{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP5SJu5nbT2LtysY4eoVD0P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SharlotteManganye/Deep-Learning-CNN/blob/main/Copy_of_Pi_CNN_V1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# visualization tools\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# torch- Our deep learning framework\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "# from other notebooks\n",
        "# import import_ipynb\n",
        "# from dataloaders import DataLoader"
      ],
      "metadata": {
        "id": "Qt5DblrsZKLw"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the transformations\n",
        "transform = transforms.Compose([\n",
        "    ToTensor(),\n",
        "    transforms.Normalize(mean=[0.1310], std=[0.3085])\n",
        "])\n",
        "\n",
        "# Load the training data\n",
        "train_data = datasets.MNIST(\n",
        "    root='data',\n",
        "    train=True,\n",
        "    transform=transform,\n",
        "    download=True,\n",
        ")\n",
        "\n",
        "# Load the test data\n",
        "test_data = datasets.MNIST(\n",
        "    root='data',\n",
        "    train=False,\n",
        "    transform=transform,\n",
        ")"
      ],
      "metadata": {
        "id": "NDyXd43HZHXz"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_data,\n",
        "                                          batch_size=100,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=1)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_data,\n",
        "                                          batch_size=100,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=1)"
      ],
      "metadata": {
        "id": "9MCLLjq0Zay8"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k8Xo5AyYz442"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "iOjSOUxyFIJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "class PiCon2D(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1,pool_kernel_size=2, padding=0):\n",
        "        super(PiCon2D, self).__init__()\n",
        "        self.kernel_size = (kernel_size, kernel_size)\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.pool_kernel_size = (pool_kernel_size,pool_kernel_size)\n",
        "\n",
        "        # Initialize weights\n",
        "        # DO NOT STORE WEIGHT EXTERNALLY YOU NEED MORE FOR MORE THAN ONE LAYER\n",
        "        self.weight = nn.Parameter(torch.Tensor(out_channels, in_channels, kernel_size, kernel_size))\n",
        "\n",
        "        # self.bias = nn.Parameter(torch.Tensor(out_channels))\n",
        "\n",
        "        # Apply Kaiming uniform initialization to the weights\n",
        "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
        "\n",
        "        # Initialize the bias to zeros\n",
        "        # fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
        "        # bound = 1 / math.sqrt(fan_in)\n",
        "        # nn.init.uniform_(self.bias, -bound, bound)\n",
        "\n",
        "        # Define an activation function (ReLU in this case)\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "        # Define a max-pooling layer\n",
        "        self.pool = nn.MaxPool2d(kernel_size=pool_kernel_size)\n",
        "\n",
        "        # To store the feature maps\n",
        "        self.feature_maps = None\n",
        "\n",
        "\n",
        "\n",
        "    def pi_conv2d(self, input, weight, stride=1, padding=0):\n",
        "      batch_size, in_channels, in_h, in_w = input.shape\n",
        "      out_channels, _, kh, kw = weight.shape\n",
        "\n",
        "       # Calculate output dimensions\n",
        "      out_h = (in_h + 2 * padding - kh) // stride + 1\n",
        "      out_w = (in_w + 2 * padding - kw) // stride + 1\n",
        "\n",
        "      # Unfold input tensor\n",
        "      unfold = torch.nn.Unfold(kernel_size=(kh, kw), stride=stride, padding=padding)\n",
        "\n",
        "      inp_unf = unfold(input)  # Shape: [batch_size, in_channels * kh * kw, out_h * out_w]\n",
        "\n",
        "\n",
        "      # Reshape weight for matrix multiplication\n",
        "      in_channels = weight.size(1)\n",
        "      w_ = weight.view(out_channels, in_channels * kh * kw)  # Shape: [out_channels, in_channels * kh * kw]\n",
        "\n",
        "\n",
        "      # Apply absolute value and logarithmic transformation with clamping\n",
        "      abs_inp_unf = torch.abs(inp_unf)\n",
        "      log_abs_inp_unf = torch.log(abs_inp_unf)  # Logarithm with clamping\n",
        "\n",
        "      # Matrix multiplication for positive values\n",
        "      log_abs_inp_unf_t = log_abs_inp_unf.transpose(1, 2)  # Shape: [batch_size, out_h * out_w, in_channels * kh * kw]\n",
        "      sum_log = torch.matmul(log_abs_inp_unf_t, w_.t())  # Compute sum of logs\n",
        "      # sum_log = torch.clamp(sum_log, min=-50, max=50)  # Clamping to prevent overflow in exp\n",
        "      part_one = torch.exp(sum_log)  # Shape: [batch_size, out_h * out_w, out_channels]\n",
        "\n",
        "      # Create a mask for negative values (for weights)\n",
        "      negative_mask = (inp_unf < 0).float()\n",
        "\n",
        "      # Compute the sum of weights where inputs are negative\n",
        "      sum_weights = torch.matmul(negative_mask.transpose(1, 2), w_.t())  # Shape: [batch_size, out_h * out_w, out_channels]\n",
        "      cos_w = torch.cos(math.pi * sum_weights)  # Shape: [batch_size, out_h * out_w, out_channels]\n",
        "\n",
        "      # part_two should have the same shape as part_one\n",
        "      part_two = part_one * cos_w  # Shape: [batch_size, out_h * out_w, out_channels]\n",
        "\n",
        "\n",
        "      # Align positive mask dimensions for element-wise operations\n",
        "      positive_mask = (inp_unf > 0)  # Remove unsqueeze here\n",
        "\n",
        "      # Expand positive_mask correctly to 3D and match output channels\n",
        "      positive_mask = positive_mask.transpose(1, 2)  # Shape: [batch_size, out_h * out_w, in_channels * kh * kw]\n",
        "      positive_mask = positive_mask[..., :1]  # Reduce to only one dimension before expanding\n",
        "      positive_mask = positive_mask.expand(batch_size, out_h * out_w, out_channels)  # Shape: [batch_size, out_h * out_w, out_channels]\n",
        "\n",
        "     # Apply torch.where with correctly aligned tensors\n",
        "      out = torch.where(positive_mask, part_one, part_two)  # Ensure the shapes match\n",
        "      out = out.view(batch_size, out_channels, out_h, out_w)  # Reshape back to 4D tensor\n",
        "\n",
        "      # Store the feature maps\n",
        "      self.feature_maps = out\n",
        "\n",
        "      return out\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "       # Apply PiConv2D for feature extraction\n",
        "        print(x.shape)\n",
        "        y = self.pi_conv2d(x, self.weight, self.stride, self.padding)  # Feature extraction\n",
        "        z = nn.Conv2d(self.in_channels, self.out_channels, 3, self.stride,self.padding)\n",
        "        z_out = z(x)\n",
        "        combined = torch.cat((y, z_out), dim=1)  # Concatenate along the channel dimension\n",
        "        out =self.activation(combined)\n",
        "        out = out.view(out.size(0), -1)  # Flatten the tensor\n",
        "        in_features = out.size(1)  # Dynamically set input size)\n",
        "\n",
        "        # Define the fully connected layers with the concatenated input\n",
        "        fc = nn.Sequential(\n",
        "            nn.Linear(in_features, 128),  # in_features is dynamically set\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10)  # Output size is 10 for 10 classes (digits 0-9)\n",
        "        )\n",
        "        # Pass the concatenated features through the fully connected layers\n",
        "        output  = fc(combined)\n",
        "\n",
        "        return F.log_softmax(output , dim=1)  # Softmax activation for classification\n"
      ],
      "metadata": {
        "id": "qdvQ9zxdWjVp"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "M4yDT4C1-gvb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = PiCon2D(1,32)"
      ],
      "metadata": {
        "id": "eHHXqM7uYOlr"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss function\n",
        "loss_func = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "HDxn3tmPYGf5"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adam optimizer\n",
        "# optimizer = optim.Adam(model.parameters(), lr = 0.01, weight_decay=1e-4)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ],
      "metadata": {
        "id": "mRLpzbZOYgE5"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        data, target = data, target\n",
        "\n",
        "        output = model(data)\n",
        "\n",
        "        # Ensure output shape: [batch_size, num_classes]\n",
        "        # Ensure target shape: [batch_size] with class indices\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = loss_func(output, target)\n",
        "        loss.backward()\n",
        "       #Clip gradients\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        _, pred = output.max(1)  # Get the predicted class\n",
        "        train_acc += target.eq(pred).sum().item()\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "    train_acc /= len(train_loader.dataset)  # Correctly normalize accuracy\n",
        "\n",
        "    return train_loss, train_acc * 100  # Convert accuracy to percentage\n"
      ],
      "metadata": {
        "id": "ftCltD34Yk_E"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def val():\n",
        "    # setting model in evaluation mode.\n",
        "    model.eval()\n",
        "\n",
        "    val_loss = 0\n",
        "    val_acc = 0\n",
        "\n",
        "    # no gradient is needed\n",
        "    # when calling a PyTorch neural network to compute output during TRAINING, you should NEVER use the no_grad() statement,\n",
        "    # but when NOT TRAINING, using the no_grad() statement is optional but more principled.\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(test_loader):\n",
        "\n",
        "            #FP\n",
        "            output = model(data.float())\n",
        "\n",
        "            # loss\n",
        "            val_loss += loss_func(output, target).item()\n",
        "            _, pred = output.max(1)\n",
        "            val_acc += target.eq(pred).sum().item()\n",
        "\n",
        "    val_loss /= (batch_idx + 1) # Average per batch\n",
        "    val_acc /= len(test_loader.dataset)\n",
        "    return val_loss, val_acc"
      ],
      "metadata": {
        "id": "lbZh0lYdYqeE"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check if the weights are not zeros or too close to zero\n",
        "\n",
        "\n",
        "# print(\"Min value in weights:\", model.weight.min().item())\n",
        "# print(\"Max value in weights:\", model.weight.max().item())"
      ],
      "metadata": {
        "id": "-9ZbBphP4C5h"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking and printing the features"
      ],
      "metadata": {
        "id": "Us_gc6g03-6R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"Min value in feature maps:\", feature_maps.min().item())\n",
        "# print(\"Max value in feature maps:\", feature_maps.max().item())\n"
      ],
      "metadata": {
        "id": "n2FJ-clK3bSp"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Pass a batch of images through the model\n",
        "# data_iter = iter(train_loader)\n",
        "# images, labels = next(data_iter)  # Use next() function instead of .next()\n",
        "\n",
        "# # Get the model output\n",
        "# output = model(images)\n",
        "\n",
        "# # Get the feature maps from the model\n",
        "# feature_maps = model.feature_maps\n",
        "\n",
        "# # Plot the feature maps\n",
        "# def plot_feature_maps(feature_maps, n_cols=8):\n",
        "#     n_filters = feature_maps.shape[1]\n",
        "#     n_rows = (n_filters + n_cols - 1) // n_cols\n",
        "\n",
        "#     fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, n_rows * 2))\n",
        "#     for i in range(n_rows):\n",
        "#         for j in range(n_cols):\n",
        "#             idx = i * n_cols + j\n",
        "#             if idx < n_filters:\n",
        "#                 ax = axes[i, j]\n",
        "#                 ax.imshow(feature_maps[0, idx].detach().cpu().numpy(), cmap='viridis')\n",
        "#                 ax.axis('off')\n",
        "#             else:\n",
        "#                 axes[i, j].axis('off')\n",
        "#     plt.show()\n",
        "\n",
        "# plot_feature_maps(feature_maps)\n"
      ],
      "metadata": {
        "id": "OsjUef2v2kaK"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_list = []\n",
        "val_loss_list = []\n",
        "\n",
        "acc_list = []\n",
        "val_acc_list = []\n",
        "\n",
        "epochs = 10\n",
        "for epoch in range(1, epochs + 1):\n",
        "    print(\"--- Epoch {} ---\".format(epoch))\n",
        "    train_loss, train_acc = train(epoch)\n",
        "    print('\\tTrain loss: {:.4f}, acc: {:.4f}%'.format(train_loss, train_acc))\n",
        "    loss_list.append(train_loss)\n",
        "    acc_list.append(train_acc)\n",
        "    val_loss, val_acc =  val()\n",
        "    print('\\tVal loss: {:.4f}, acc: {:.4f}%'.format(val_loss, val_acc))\n",
        "    val_loss_list.append(val_loss)\n",
        "    val_acc_list.append(val_acc)"
      ],
      "metadata": {
        "id": "0v9FDUfAYtal",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "14b19db1-48b4-45de-e131-d85768764b26"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Epoch 1 ---\n",
            "torch.Size([100, 1, 28, 28])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (166400x26 and 43264x128)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-173-539d4ee6f6d9>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- Epoch {} ---\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\tTrain loss: {:.4f}, acc: {:.4f}%'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mloss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-168-1354c78d73e4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# Ensure output shape: [batch_size, num_classes]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-164-2fca0e4ae19e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    161\u001b[0m         )\n\u001b[1;32m    162\u001b[0m         \u001b[0;31m# Pass the concatenated features through the fully connected layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0moutput\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcombined\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Softmax activation for classification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    217\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (166400x26 and 43264x128)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot\n",
        "\n",
        "\n",
        "x = range(1, epochs + 1)\n",
        "\n",
        "plt.figure(figsize=(16, 5))\n",
        "\n",
        "#loss\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(x, loss_list, 'b', label = 'train')\n",
        "plt.plot(x, val_loss_list, 'r', label = 'val')\n",
        "plt.title('LOSS')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "\n",
        "#Accuracy\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(x, acc_list, 'b', label = 'train')\n",
        "plt.plot(x, val_acc_list, 'r', label = 'val')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9B4Jsf87X7QK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}