{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUv0sJ+/+vUYj2XcGvIzER",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SharlotteManganye/Deep-Learning-CNN/blob/main/CNN_CPSO_2025_02_05.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6x-frUkVD8Hf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# CNN Architecture (same as before)\n",
        "class CNN(nn.Module):\n",
        "    # ... (CNN definition - same as previous examples)\n",
        "\n",
        "# Data Loading (same as before)\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "\n",
        "# Cooperative PSO Implementation\n",
        "def cooperative_pso(fitness_function, lb, ub, swarmsize=10, maxiter=10, num_subswarms=2):  # Added num_subswarms\n",
        "    n_dimensions = len(lb)\n",
        "    personal_bests = np.zeros((swarmsize, n_dimensions))\n",
        "    personal_best_fitness = np.full(swarmsize, -np.inf)  # Initialize with negative infinity\n",
        "    global_best = np.zeros(n_dimensions)\n",
        "    global_best_fitness = -np.inf\n",
        "\n",
        "    # Initialize swarm positions and velocities (using numpy for efficiency)\n",
        "    swarm = np.random.uniform(lb, ub, size=(swarmsize, n_dimensions))\n",
        "    velocity = np.random.uniform(-abs(ub - lb) / 2, abs(ub - lb) / 2, size=(swarmsize, n_dimensions)) # Init velocity\n",
        "\n",
        "    all_train_losses = [[] for _ in range(swarmsize)]\n",
        "    all_val_losses = [[] for _ in range(swarmsize)]\n",
        "    all_train_accuracies = [[] for _ in range(swarmsize)]\n",
        "    all_val_accuracies = [[] for _ in range(swarmsize)]\n",
        "\n",
        "    for i in range(maxiter):\n",
        "        # Divide swarm into subswarms\n",
        "        subswarm_size = swarmsize // num_subswarms\n",
        "        for k in range(num_subswarms):\n",
        "            start = k * subswarm_size\n",
        "            end = (k + 1) * subswarm_size if k < num_subswarms - 1 else swarmsize\n",
        "            subswarm_indices = range(start, end)\n",
        "\n",
        "            # Find subswarm best\n",
        "            subswarm_best = np.zeros(n_dimensions)\n",
        "            subswarm_best_fitness = -np.inf\n",
        "\n",
        "            for j in subswarm_indices:\n",
        "                fitness, train_losses, val_losses, train_accuracies, val_accuracies = fitness_function(swarm[j])\n",
        "                all_train_losses[j].extend(train_losses)\n",
        "                all_val_losses[j].extend(val_losses)\n",
        "                all_train_accuracies[j].extend(train_accuracies)\n",
        "                all_val_accuracies[j].extend(val_accuracies)\n",
        "\n",
        "                if fitness > personal_best_fitness[j]:\n",
        "                    personal_best_fitness[j] = fitness\n",
        "                    personal_bests[j] = swarm[j]\n",
        "\n",
        "                if fitness > subswarm_best_fitness:\n",
        "                    subswarm_best_fitness = fitness\n",
        "                    subswarm_best = swarm[j]\n",
        "\n",
        "                if fitness > global_best_fitness:\n",
        "                    global_best_fitness = fitness\n",
        "                    global_best = swarm[j]\n",
        "\n",
        "            # Update velocities and positions (using subswarm best and global best)\n",
        "            inertia_weight = 0.729  # Adjust as needed\n",
        "            cognitive_coeff = 1.49445  # Adjust as needed\n",
        "            social_coeff = 1.49445  # Adjust as needed\n",
        "\n",
        "            r1 = np.random.rand(len(subswarm_indices), n_dimensions)\n",
        "            r2 = np.random.rand(len(subswarm_indices), n_dimensions)\n",
        "\n",
        "            velocity[subswarm_indices] = (inertia_weight * velocity[subswarm_indices] +\n",
        "                                        cognitive_coeff * r1 * (personal_bests[subswarm_indices] - swarm[subswarm_indices]) +\n",
        "                                        social_coeff * r2 * (np.tile(subswarm_best, (len(subswarm_indices), 1)) - swarm[subswarm_indices]))\n",
        "\n",
        "            swarm[subswarm_indices] = np.clip(swarm[subswarm_indices] + velocity[subswarm_indices], lb, ub) # Clip swarm to bounds\n",
        "\n",
        "    return global_best_fitness, global_best, all_train_losses, all_val_losses, all_train_accuracies, all_val_accuracies\n",
        "\n",
        "\n",
        "# Fitness Function (same structure, but now uses numpy arrays)\n",
        "def fitness_function(particle):\n",
        "    learning_rate = 10**particle[0]\n",
        "    batch_size = int(2**particle[1])\n",
        "\n",
        "    train_loader_pso = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader_pso = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    model = CNN()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    num_epochs = 3  # Reduced for PSO\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      # ... (Training and validation loops - same as before, using train_loader_pso and test_loader_pso)\n",
        "        train_losses.append(avg_train_loss)\n",
        "        val_losses.append(avg_val_loss)\n",
        "        train_accuracies.append(train_accuracy)\n",
        "        val_accuracies.append(val_accuracy)\n",
        "\n",
        "    accuracy = val_accuracy\n",
        "    return accuracy, train_losses, val_losses, train_accuracies, val_accuracies\n",
        "\n",
        "\n",
        "# PSO Parameters (same as before)\n",
        "n_particles = 20 # Increased number of particles\n",
        "n_dimensions = 2\n",
        "iterations = 20 # Increased number of iterations\n",
        "num_subswarms = 4 # Added number of subswarms\n",
        "\n",
        "lb = [-5, 8]\n",
        "ub = [0, 8]\n",
        "\n",
        "# Run Cooperative PSO\n",
        "best_accuracy, best_hyperparameters, all_train_losses, all_val_losses, all_train_accuracies, all_val_accuracies = cooperative_pso(\n",
        "    fitness_function, lb, ub, swarmsize=n_particles, maxiter=iterations, num_subswarms=num_subswarms\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "print(\"Best Accuracy:\", best_accuracy)\n",
        "print(\"Best Hyperparameters (learning rate exponent, batch size exponent):\", best_hyperparameters)\n",
        "print(\"Best Learning Rate:\", 10**best_hyperparameters[0])\n",
        "print(\"Best Batch Size:\", int(2**best_hyperparameters[1]))\n",
        "\n",
        "# Plotting (after Cooperative PSO) - Corrected and filled in\n",
        "# ... (same plotting code as before)\n",
        "\n",
        "# Final Training (same as before)\n",
        "# ... (same final training loop and plotting as before)"
      ]
    }
  ]
}