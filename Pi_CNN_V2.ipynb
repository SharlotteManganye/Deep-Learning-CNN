{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SharlotteManganye/Deep-Learning-CNN/blob/main/Pi_CNN_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qt5DblrsZKLw"
      },
      "outputs": [],
      "source": [
        "\n",
        "# visualization tools\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# torch- Our deep learning framework\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "# from other notebooks\n",
        "# import import_ipynb\n",
        "# from dataloaders import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDyXd43HZHXz",
        "outputId": "02db8a2e-e7e7-4806-8526-42233bb4fed3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 16019240.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 489670.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1648877/1648877 [00:01<00:00, 1326346.46it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 8239848.08it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Define the transformations\n",
        "transform = transforms.Compose([\n",
        "    ToTensor(),\n",
        "    transforms.Normalize(mean=[0.1310], std=[0.3085])\n",
        "])\n",
        "\n",
        "# Load the training data\n",
        "train_data = datasets.MNIST(\n",
        "    root='data',\n",
        "    train=True,\n",
        "    transform=transform,\n",
        "    download=True,\n",
        ")\n",
        "\n",
        "# Load the test data\n",
        "test_data = datasets.MNIST(\n",
        "    root='data',\n",
        "    train=False,\n",
        "    transform=transform,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MCLLjq0Zay8"
      },
      "outputs": [],
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_data,\n",
        "                                          batch_size=100,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=1)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(test_data,\n",
        "                                          batch_size=100,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8Xo5AyYz442"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOjSOUxyFIJR"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdvQ9zxdWjVp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "class PiCon2D(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, pool_kernel_size=2, padding=0):\n",
        "        super(PiCon2D, self).__init__()\n",
        "        self.kernel_size = (kernel_size, kernel_size)\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.pool_kernel_size = (pool_kernel_size, pool_kernel_size)\n",
        "\n",
        "        # Initialize weights for each layer\n",
        "        self.weight1 = nn.Parameter(torch.Tensor(out_channels, in_channels, kernel_size, kernel_size))\n",
        "        self.weight2 = nn.Parameter(torch.Tensor(out_channels, out_channels, kernel_size, kernel_size))\n",
        "        self.weight3 = nn.Parameter(torch.Tensor(out_channels, out_channels, kernel_size, kernel_size))\n",
        "\n",
        "        # Apply Kaiming uniform initialization to the weights\n",
        "        nn.init.kaiming_uniform_(self.weight1, a=math.sqrt(5))\n",
        "        nn.init.kaiming_uniform_(self.weight2, a=math.sqrt(5))\n",
        "        nn.init.kaiming_uniform_(self.weight3, a=math.sqrt(5))\n",
        "\n",
        "        # Define an activation function (ReLU in this case)\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "        # Define a max-pooling layer\n",
        "        self.pool = nn.MaxPool2d(kernel_size=pool_kernel_size)\n",
        "\n",
        "        # To store the feature maps\n",
        "        self.feature_maps = None\n",
        "\n",
        "        # Additional convolutional layers\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, stride, padding)\n",
        "        self.conv3 = nn.Conv2d(out_channels, out_channels, kernel_size, stride, padding)\n",
        "        self.conv4 = nn.Conv2d(out_channels, out_channels, kernel_size, stride, padding)\n",
        "\n",
        "    def pi_conv2d(self, input, weight, stride=1, padding=0):\n",
        "        batch_size, in_channels, in_h, in_w = input.shape\n",
        "        out_channels, _, kh, kw = weight.shape\n",
        "\n",
        "        # Calculate output dimensions\n",
        "        out_h = (in_h + 2 * padding - kh) // stride + 1\n",
        "        out_w = (in_w + 2 * padding - kw) // stride + 1\n",
        "\n",
        "        # Unfold input tensor\n",
        "        unfold = torch.nn.Unfold(kernel_size=(kh, kw), stride=stride, padding=padding)\n",
        "        inp_unf = unfold(input)  # Shape: [batch_size, in_channels * kh * kw, out_h * out_w]\n",
        "\n",
        "        # Reshape weight for matrix multiplication\n",
        "        w_ = weight.view(out_channels, in_channels * kh * kw)  # Shape: [out_channels, in_channels * kh * kw]\n",
        "\n",
        "        # Apply absolute value and logarithmic transformation with clamping\n",
        "        abs_inp_unf = torch.abs(inp_unf)\n",
        "        log_abs_inp_unf = torch.log(abs_inp_unf)  # Logarithm with clamping\n",
        "\n",
        "        # Matrix multiplication for positive values\n",
        "        log_abs_inp_unf_t = log_abs_inp_unf.transpose(1, 2)  # Shape: [batch_size, out_h * out_w, in_channels * kh * kw]\n",
        "        sum_log = torch.matmul(log_abs_inp_unf_t, w_.t())  # Compute sum of logs\n",
        "        part_one = torch.exp(sum_log)  # Shape: [batch_size, out_h * out_w, out_channels]\n",
        "\n",
        "        # Create a mask for negative values (for weights)\n",
        "        negative_mask = (inp_unf < 0).float()\n",
        "\n",
        "        # Compute the sum of weights where inputs are negative\n",
        "        sum_weights = torch.matmul(negative_mask.transpose(1, 2), w_.t())  # Shape: [batch_size, out_h * out_w, out_channels]\n",
        "        cos_w = torch.cos(math.pi * sum_weights)  # Shape: [batch_size, out_h * out_w, out_channels]\n",
        "\n",
        "        # part_two should have the same shape as part_one\n",
        "        part_two = part_one * cos_w  # Shape: [batch_size, out_h * out_w, out_channels]\n",
        "\n",
        "        # Align positive mask dimensions for element-wise operations\n",
        "        positive_mask = (inp_unf > 0)  # Remove unsqueeze here\n",
        "\n",
        "        # Expand positive_mask correctly to 3D and match output channels\n",
        "        positive_mask = positive_mask.transpose(1, 2)  # Shape: [batch_size, out_h * out_w, in_channels * kh * kw]\n",
        "        positive_mask = positive_mask[..., :1]  # Reduce to only one dimension before expanding\n",
        "        positive_mask = positive_mask.expand(batch_size, out_h * out_w, out_channels)  # Shape: [batch_size, out_h * out_w, out_channels]\n",
        "\n",
        "        # Apply torch.where with correctly aligned tensors\n",
        "        out = torch.where(positive_mask, part_one, part_two)  # Ensure the shapes match\n",
        "        out = out.view(batch_size, out_channels, out_h, out_w)  # Reshape back to 4D tensor\n",
        "\n",
        "        # Store the feature maps\n",
        "        self.feature_maps = out\n",
        "\n",
        "        return out\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply PiConv2D for feature extraction\n",
        "        y = self.pi_conv2d(x, self.weight1, self.stride, self.padding)  # Feature extraction\n",
        "        y = self.pi_conv2d(y, self.weight2, self.stride, self.padding)  # Feature extraction\n",
        "        y = self.pi_conv2d(y, self.weight3, self.stride, self.padding)  # Feature extraction\n",
        "\n",
        "        # Standard convolutional layers\n",
        "        z1 = self.conv1(x)\n",
        "        z2 = self.conv2(z1)\n",
        "        z3 = self.conv3(z2)\n",
        "        z4 = self.conv4(z3)\n",
        "\n",
        "        # Ensure the output dimensions match before concatenation\n",
        "        if y.size(2) != z4.size(2) or y.size(3) != z4.size(3):\n",
        "            diff_h = y.size(2) - z4.size(2)\n",
        "            diff_w = y.size(3) - z4.size(3)\n",
        "            z4 = F.pad(z4, (0, diff_w, 0, diff_h))\n",
        "\n",
        "        # Concatenate along the channel dimension\n",
        "        combined = torch.cat((y, z4), dim=1)\n",
        "        combined = combined.view(combined.size(0), -1)\n",
        "        out = self.activation(combined)\n",
        "        out = out.view(out.size(0), -1)  # Flatten the tensor\n",
        "        in_features = out.size(1)  # Dynamically set input size\n",
        "\n",
        "        # Define the fully connected layers with the concatenated input\n",
        "        fc = nn.Sequential(\n",
        "            nn.Linear(in_features, 128),  # in_features is dynamically set\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10)  # Output size is 10 for 10 classes (digits 0-9)\n",
        "        )\n",
        "\n",
        "        # Pass the concatenated features through the fully connected layers\n",
        "        output = fc(out)\n",
        "\n",
        "        return F.log_softmax(output, dim=1)  # Softmax activation for classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M4yDT4C1-gvb"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eHHXqM7uYOlr"
      },
      "outputs": [],
      "source": [
        "\n",
        "model = PiCon2D(1,32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDxn3tmPYGf5"
      },
      "outputs": [],
      "source": [
        "# loss function\n",
        "loss_func = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRLpzbZOYgE5"
      },
      "outputs": [],
      "source": [
        "# Adam optimizer\n",
        "# optimizer = optim.Adam(model.parameters(), lr = 0.01, weight_decay=1e-4)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ftCltD34Yk_E"
      },
      "outputs": [],
      "source": [
        "def train(epoch):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    train_acc = 0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        data, target = data, target\n",
        "\n",
        "        output = model(data)\n",
        "\n",
        "        # Ensure output shape: [batch_size, num_classes]\n",
        "        # Ensure target shape: [batch_size] with class indices\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = loss_func(output, target)\n",
        "        loss.backward()\n",
        "       #Clip gradients\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        # Calculate accuracy\n",
        "        _, pred = output.max(1)  # Get the predicted class\n",
        "        train_acc += target.eq(pred).sum().item()\n",
        "\n",
        "    train_loss /= len(train_loader)\n",
        "    train_acc /= len(train_loader.dataset)  # Correctly normalize accuracy\n",
        "\n",
        "    return train_loss, train_acc * 100  # Convert accuracy to percentage\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbZh0lYdYqeE"
      },
      "outputs": [],
      "source": [
        "def val():\n",
        "    # setting model in evaluation mode.\n",
        "    model.eval()\n",
        "\n",
        "    val_loss = 0\n",
        "    val_acc = 0\n",
        "\n",
        "    # no gradient is needed\n",
        "    # when calling a PyTorch neural network to compute output during TRAINING, you should NEVER use the no_grad() statement,\n",
        "    # but when NOT TRAINING, using the no_grad() statement is optional but more principled.\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in enumerate(test_loader):\n",
        "\n",
        "            #FP\n",
        "            output = model(data.float())\n",
        "\n",
        "            # loss\n",
        "            val_loss += loss_func(output, target).item()\n",
        "            _, pred = output.max(1)\n",
        "            val_acc += target.eq(pred).sum().item()\n",
        "\n",
        "    val_loss /= (batch_idx + 1) # Average per batch\n",
        "    val_acc /= len(test_loader.dataset)\n",
        "    return val_loss, val_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9ZbBphP4C5h"
      },
      "outputs": [],
      "source": [
        "# check if the weights are not zeros or too close to zero\n",
        "\n",
        "\n",
        "# print(\"Min value in weights:\", model.weight.min().item())\n",
        "# print(\"Max value in weights:\", model.weight.max().item())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Us_gc6g03-6R"
      },
      "source": [
        "Checking and printing the features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2FJ-clK3bSp"
      },
      "outputs": [],
      "source": [
        "# print(\"Min value in feature maps:\", feature_maps.min().item())\n",
        "# print(\"Max value in feature maps:\", feature_maps.max().item())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OsjUef2v2kaK"
      },
      "outputs": [],
      "source": [
        "# # Pass a batch of images through the model\n",
        "# data_iter = iter(train_loader)\n",
        "# images, labels = next(data_iter)  # Use next() function instead of .next()\n",
        "\n",
        "# # Get the model output\n",
        "# output = model(images)\n",
        "\n",
        "# # Get the feature maps from the model\n",
        "# feature_maps = model.feature_maps\n",
        "\n",
        "# # Plot the feature maps\n",
        "# def plot_feature_maps(feature_maps, n_cols=8):\n",
        "#     n_filters = feature_maps.shape[1]\n",
        "#     n_rows = (n_filters + n_cols - 1) // n_cols\n",
        "\n",
        "#     fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, n_rows * 2))\n",
        "#     for i in range(n_rows):\n",
        "#         for j in range(n_cols):\n",
        "#             idx = i * n_cols + j\n",
        "#             if idx < n_filters:\n",
        "#                 ax = axes[i, j]\n",
        "#                 ax.imshow(feature_maps[0, idx].detach().cpu().numpy(), cmap='viridis')\n",
        "#                 ax.axis('off')\n",
        "#             else:\n",
        "#                 axes[i, j].axis('off')\n",
        "#     plt.show()\n",
        "\n",
        "# plot_feature_maps(feature_maps)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "0v9FDUfAYtal",
        "outputId": "05bab901-5ce7-41b3-d3c2-1b053241c93b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Epoch 1 ---\n",
            "\tTrain loss: 2.3307, acc: 9.9167%\n",
            "\tVal loss: 2.3294, acc: 0.1034%\n",
            "--- Epoch 2 ---\n",
            "\tTrain loss: 2.3287, acc: 10.1017%\n",
            "\tVal loss: 2.3297, acc: 0.0984%\n",
            "--- Epoch 3 ---\n",
            "\tTrain loss: 2.3332, acc: 10.0467%\n",
            "\tVal loss: 2.3252, acc: 0.1043%\n",
            "--- Epoch 4 ---\n"
          ]
        }
      ],
      "source": [
        "loss_list = []\n",
        "val_loss_list = []\n",
        "\n",
        "acc_list = []\n",
        "val_acc_list = []\n",
        "\n",
        "epochs = 10\n",
        "for epoch in range(1, epochs + 1):\n",
        "    print(\"--- Epoch {} ---\".format(epoch))\n",
        "    train_loss, train_acc = train(epoch)\n",
        "    print('\\tTrain loss: {:.4f}, acc: {:.4f}%'.format(train_loss, train_acc))\n",
        "    loss_list.append(train_loss)\n",
        "    acc_list.append(train_acc)\n",
        "    val_loss, val_acc =  val()\n",
        "    print('\\tVal loss: {:.4f}, acc: {:.4f}%'.format(val_loss, val_acc))\n",
        "    val_loss_list.append(val_loss)\n",
        "    val_acc_list.append(val_acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9B4Jsf87X7QK"
      },
      "outputs": [],
      "source": [
        "# plot\n",
        "\n",
        "\n",
        "x = range(1, epochs + 1)\n",
        "\n",
        "plt.figure(figsize=(16, 5))\n",
        "\n",
        "#loss\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(x, loss_list, 'b', label = 'train')\n",
        "plt.plot(x, val_loss_list, 'r', label = 'val')\n",
        "plt.title('LOSS')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "\n",
        "#Accuracy\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(x, acc_list, 'b', label = 'train')\n",
        "plt.plot(x, val_acc_list, 'r', label = 'val')\n",
        "plt.title('Accuracy')\n",
        "plt.xlabel('epochs')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyM/uCMnQXPvsrLcoeY9Zwsk",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}