{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SharlotteManganye/Deep-Learning-CNN/blob/main/Mnist_wider_HLA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "18LDq8nMpW0W"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch.autograd import Function\n",
        "import torch.nn as nn\n",
        "from torchvision.datasets import MNIST\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms.autoaugment import AutoAugmentPolicy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Efficient_High_order_conv file"
      ],
      "metadata": {
        "id": "ILM6Y4X0pY3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def PM_creation( N, input_size, TRM):\n",
        "    index = []\n",
        "    PM = torch.arange(input_size)[:,None]\n",
        "    TPM = []\n",
        "    TPM.append(PM)\n",
        "    PM_full = []\n",
        "    for i in range(N-1):\n",
        "        Nc = int(PM.shape[1])\n",
        "        for j in range(input_size-Nc):\n",
        "            j = j+1\n",
        "            p_N1 = (PM[:,Nc-1] + j)[:, None]\n",
        "            index_chosen = torch.argwhere(p_N1 < input_size)\n",
        "            index_final = torch.concat((PM[index_chosen[:,0]],p_N1[index_chosen[:,0]]), axis = 1)\n",
        "            index.append(index_final)\n",
        "            p_N1 = p_N1 - j\n",
        "        PM = torch.vstack(index)\n",
        "        index = []\n",
        "        TPM.append(PM)\n",
        "    for k in range(len(TRM)):\n",
        "        PM = TPM[len(TRM[k])-1]\n",
        "        PM_full.append(np.repeat(PM, TRM[k], axis =1))\n",
        "    PM_full = torch.vstack(PM_full)\n",
        "    return PM_full\n",
        "\n",
        "\n",
        "def PCM_creation(PM_full_r_1, PM_full_r):\n",
        "    PCM_r = []\n",
        "    PCMs_r = []\n",
        "    for i in range(PM_full_r.shape[1]):\n",
        "        PM_deleted = torch.cat((PM_full_r[:, :i], PM_full_r[:, i + 1:]), dim=1)\n",
        "        for row_r in PM_deleted:\n",
        "            Position = torch.where(torch.all(PM_full_r_1 ==row_r, axis = 1))\n",
        "            PCM_r.append(torch.tensor(Position))\n",
        "        PCM_r = torch.vstack(PCM_r)\n",
        "        PCM_r = torch.concat((PM_full_r[:,i][:,None], PCM_r), axis = 1)\n",
        "        PCMs_r.append(PCM_r)\n",
        "        PCM_r = []\n",
        "    return  PCMs_r\n",
        "\n",
        "\n",
        "class HT_creation(Function):\n",
        "        @staticmethod\n",
        "        def forward(ctx, input, kernel_size, stride, padding,\n",
        "                  TPCMs_r):\n",
        "            input = input.to(device)\n",
        "            shape = input.shape\n",
        "            grad_move = []\n",
        "            grad_move.append(0)\n",
        "            x_r_1_move =[]\n",
        "            x_r_1_move.append(0)\n",
        "            HT = []\n",
        "            unfold = nn.Unfold(kernel_size = kernel_size,  padding = padding, stride = stride)\n",
        "            Col = unfold(input)\n",
        "            weight_shape = []\n",
        "\n",
        "            ori_col = int(kernel_size[0]*kernel_size[1])\n",
        "            Col = Col.view(shape[0], shape[1], ori_col, Col.shape[-1])\n",
        "\n",
        "            for i in range(len(TPCMs_r)):\n",
        "                if i == 0:\n",
        "                    grad_move.append(grad_move[i]+TPCMs_r[i][0].shape[0])\n",
        "                    weight_shape.append((ori_col, ori_col))\n",
        "                    HT.append(Col[:,:,TPCMs_r[i][0][:,0],:]*Col[:,:,TPCMs_r[i][0][:,1],:])\n",
        "                    x_r_1_move.append(x_r_1_move[i]+Col.shape[2])\n",
        "                else:\n",
        "                    grad_move.append(grad_move[i]+TPCMs_r[i][0].shape[0])\n",
        "                    weight_shape.append((TPCMs_r[i-1][0].shape[0], ori_col))\n",
        "                    HT.append(Col[:,:,TPCMs_r[i][0][:,0],:]*HT[i-1][:,:,TPCMs_r[i][0][:,1],:])\n",
        "                    x_r_1_move.append(x_r_1_move[i]+TPCMs_r[i-1][0].shape[0])\n",
        "            HT = torch.cat(HT, dim = 2)\n",
        "            if len(TPCMs_r) == 1:\n",
        "                # ctx.back_terms = Col\n",
        "                ctx.save_for_backward(Col)\n",
        "            else:\n",
        "                # ctx.back_terms = torch.cat((Col,HT[:,:,0:grad_move[-2],:]), dim=2 )\n",
        "                ctx.save_for_backward(torch.cat((Col,HT[:,:,0:grad_move[-2],:]), dim=2 ))\n",
        "            ctx.grad_move = grad_move\n",
        "            ctx.x_r_1_move = x_r_1_move\n",
        "            ctx.TPCMs_r = TPCMs_r\n",
        "\n",
        "            ctx.weight_shape = weight_shape\n",
        "            ctx.kernel_size =kernel_size\n",
        "            ctx.stride = stride\n",
        "            ctx.padding = padding\n",
        "            ctx.shape =shape\n",
        "\n",
        "            return HT\n",
        "        @staticmethod\n",
        "        def backward(ctx, grad):\n",
        "            (back_terms,) = ctx.saved_tensors\n",
        "\n",
        "            # back_terms = ctx.back_terms\n",
        "            weight_shape = ctx.weight_shape\n",
        "            TPCMs_r = ctx.TPCMs_r\n",
        "            kernel_size = ctx.kernel_size\n",
        "            stride = ctx.stride\n",
        "            padding = ctx.padding\n",
        "            shape = ctx.shape\n",
        "            grad_move = ctx.grad_move\n",
        "            x_r_1_move = ctx.x_r_1_move\n",
        "            grad_input  = None\n",
        "\n",
        "            for i in range(len(TPCMs_r)):\n",
        "                Al_grad = torch.zeros((grad.shape[0], grad.shape[1],\n",
        "                                          weight_shape[i][0], weight_shape[i][1],grad.shape[-1])).to(device)\n",
        "                if i == 0:\n",
        "                    Al_grad[:,:, TPCMs_r[0][0][:,0],TPCMs_r[0][0][:,1],:] = grad[:,:,grad_move[0]:grad_move[1],:]\n",
        "                    # Al_grad[:,:, PCMs_r[0][:,1],PCMs_r[0][:,0],:] += grad[:,:,grad_move[0]:grad_move[1],:]\n",
        "                    Al_grad = Al_grad + Al_grad.transpose(2,3)\n",
        "                    grad_input = torch.einsum('bcikj,bckj->bcij',Al_grad,\n",
        "                                              back_terms[:,:,x_r_1_move[0]:x_r_1_move[1],:])\n",
        "                else:\n",
        "                    Al_grad[:,:, TPCMs_r[i][0][:,1], TPCMs_r[i][0][:,0],:] = grad[:,:,grad_move[i]:grad_move[i+1],:]\n",
        "                    for j in range(i+1):\n",
        "                        Al_grad[:,:, TPCMs_r[i][j+1][:,1], TPCMs_r[i][j+1][:,0],:] +=grad[:,:,grad_move[i]:grad_move[i+1],:]\n",
        "                    grad_input += torch.einsum('bckij,bckj->bcij',Al_grad,\n",
        "                                                back_terms[:,:,x_r_1_move[i]:x_r_1_move[i+1],:])\n",
        "            grad_input = grad_input.reshape(grad_input.shape[0],\n",
        "                                          grad_input.shape[1]*grad_input.shape[2], grad_input.shape[-1])\n",
        "            fold = nn.Fold((shape[-2], shape[-1]), kernel_size =kernel_size, stride = stride, padding = padding )\n",
        "            grad_input = fold(grad_input)\n",
        "\n",
        "            return grad_input, None, None, None, None, None\n",
        "\n",
        "class high_order_input(nn.Module):\n",
        "    def __init__(self, kernel_size, stride, padding, TPCMs_r):\n",
        "        super().__init__()\n",
        "        self.func = HT_creation\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.TPCMs_r = TPCMs_r\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.func.apply(input,\n",
        "                          self.kernel_size,\n",
        "                          self.stride,\n",
        "                          self.padding,\n",
        "                          self.TPCMs_r\n",
        "                          )\n",
        "\n",
        "\n",
        "class HO_conv(nn.Module):\n",
        "    def __init__(self, in_chan , out_chan, kernel_size, stride, padding, groups, TPCMs_r):\n",
        "        super().__init__()\n",
        "        self.kernel_size = kernel_size\n",
        "        self.padding =  padding\n",
        "        self.stride = stride\n",
        "        self.TPCMs_r = TPCMs_r\n",
        "        self.H_kernel_size = 0\n",
        "        for i in range(len(self.TPCMs_r)):\n",
        "\n",
        "            size = self.TPCMs_r[i][0].shape[0]\n",
        "\n",
        "            self.H_kernel_size += size\n",
        "        self.conv =  nn.Sequential( high_order_input( self.kernel_size,\n",
        "                                                self.stride,\n",
        "                                                self.padding,\n",
        "                                                self.TPCMs_r),\n",
        "                                    nn.Conv2d(in_chan, out_chan,\n",
        "                                              kernel_size=(self.H_kernel_size,1),\n",
        "                                              stride = 1,\n",
        "                                              groups = groups, bias = False))\n",
        "    def forward(self,input):\n",
        "        in_shape = input.shape\n",
        "        x = self.conv(input)\n",
        "        x =  x.reshape(x.shape[0],\n",
        "                        x.shape[1],\n",
        "                      (in_shape[-2]-self.kernel_size[0]+ 2* self.padding[0])//self.stride[0] + 1,\n",
        "                      (in_shape[-1]-self.kernel_size[1]+ 2* self.padding[1])//self.stride[1] + 1 )\n",
        "        return x"
      ],
      "metadata": {
        "id": "duVvvwe8pfAb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wider_net_HLA file"
      ],
      "metadata": {
        "id": "gvt70QioqDIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Cutout(object):\n",
        "    \"\"\"Randomly mask out one or more patches from an image.\n",
        "\n",
        "    Args:\n",
        "        n_holes (int): Number of patches to cut out of each image.\n",
        "        length (int): The length (in pixels) of each square patch.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_holes, length):\n",
        "        self.n_holes = n_holes\n",
        "        self.length = length\n",
        "\n",
        "    def __call__(self, img):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            img (Tensor): Tensor image of size (C, H, W).\n",
        "        Returns:\n",
        "            Tensor: Image with n_holes of dimension length x length cut out of it.\n",
        "        \"\"\"\n",
        "        h = img.size(1)\n",
        "        w = img.size(2)\n",
        "\n",
        "        mask = np.ones((h, w), np.float32)\n",
        "\n",
        "        for n in range(self.n_holes):\n",
        "            y = np.random.randint(h)\n",
        "            x = np.random.randint(w)\n",
        "\n",
        "            y1 = np.clip(y - self.length // 2, 0, h)\n",
        "            y2 = np.clip(y + self.length // 2, 0, h)\n",
        "            x1 = np.clip(x - self.length // 2, 0, w)\n",
        "            x2 = np.clip(x + self.length // 2, 0, w)\n",
        "\n",
        "            mask[y1: y2, x1: x2] = 0.\n",
        "\n",
        "        mask = torch.from_numpy(mask)\n",
        "        mask = mask.expand_as(img)\n",
        "        img = img * mask\n",
        "\n",
        "        return img\n",
        "\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "      transforms.RandomCrop(28, padding = 4),\n",
        "     transforms.RandomRotation(10),  # Randomly rotate the image by up to 10 degrees\n",
        "    transforms.ToTensor(),          # Convert the image to a PyTorch tensor\n",
        "    transforms.Normalize((0.1307,), (0.3081,))  # Normalize with MNIST mean and std\n",
        "])\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),          # Convert the image to a PyTorch tensor\n",
        "    transforms.Normalize((0.1307,), (0.3081,))  # Normalize with MNIST mean and std\n",
        "])\n",
        "\n",
        "# Load CIFAR-100 dataset with data augmentation\n",
        "train_dataset = MNIST(root='./data', train=True, download=True, transform=train_transform)\n",
        "test_dataset = MNIST(root='./data', train=False, download=True, transform=test_transform)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "\n",
        "num_classes = 10\n",
        "k = 8\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class squeeze(nn.Module):\n",
        "    def __init__(self, in_chan, reduce):\n",
        "        super(squeeze, self).__init__()\n",
        "\n",
        "\n",
        "        self.squ = nn.Sequential(\n",
        "                                    nn.AdaptiveAvgPool2d(1),\n",
        "                                    nn.Conv2d(in_chan, in_chan//reduce,1),\n",
        "                                    nn.ReLU(),\n",
        "                                    nn.Conv2d(in_chan//reduce,in_chan, 1),\n",
        "                                    nn.Sigmoid()\n",
        "                                    )\n",
        "    def forward(self, input):\n",
        "        x = self.squ(input)*input\n",
        "        return x\n",
        "\n",
        "class Volconv(nn.Module):\n",
        "    def __init__(self, in_chan,out_chan, kernel_size, stride, padding, groups):\n",
        "        super(Volconv, self).__init__()\n",
        "        input_size = int(kernel_size[0]*kernel_size[1])\n",
        "        # PM1_Full = torch.arange(input_size)[:,None]\n",
        "        TRM2 = [[2],[1,1]]\n",
        "        PM2_Full = PM_creation(2, input_size, TRM2)\n",
        "        # TRM3 = [[3],[1,2],[2, 1], [ 1, 1, 1]]  # Third order Toe\n",
        "        # PM3_Full = PM_creation(3, input_size, TPE3)\n",
        "        TPCMs_r = [[PM2_Full]]\n",
        "        # PCMs_r = PCM_creation(PM2_Full, PM3_Full)\n",
        "\n",
        "        self.Second_conv = nn.Sequential(\n",
        "\n",
        "                                   HO_conv(in_chan,  out_chan,\n",
        "                                              kernel_size  ,\n",
        "                                              stride  , padding, groups, TPCMs_r\n",
        "                                              ), )\n",
        "\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "                                   nn.Conv2d(in_chan, out_chan, kernel_size,\n",
        "                                              stride , padding, groups = groups, bias = False))\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.Second_conv(input)+self.conv(input)\n",
        "\n",
        "        return x\n",
        "class HLA(nn.Module):\n",
        "    def __init__(self, in_chan, kernel_size, pooling_size, padding,  in_size, reduce):\n",
        "        super(HLA, self).__init__()\n",
        "        up_size1 = in_size[0]//pooling_size[0]\n",
        "        up_size2 = in_size[1]//pooling_size[1]\n",
        "\n",
        "        self.Vol1= nn.Sequential(   nn.BatchNorm2d( in_chan),\n",
        "                                    nn.ReLU(),\n",
        "\n",
        "                                    nn.AdaptiveAvgPool2d((pooling_size[0], pooling_size[1])),\n",
        "\n",
        "                                    nn.Conv2d(in_chan, in_chan//reduce, kernel_size=1,\n",
        "                                                stride=1 , padding = 0, groups = 1),\n",
        "                                    nn.BatchNorm2d( in_chan//reduce),\n",
        "\n",
        "                                    Volconv(in_chan//reduce,in_chan//reduce, kernel_size, (1, 1), padding, 1),\n",
        "\n",
        "                                    nn.ReLU(),\n",
        "                                    nn.BatchNorm2d( in_chan//reduce),\n",
        "\n",
        "                                    nn.Conv2d(in_chan//reduce, in_chan, kernel_size=1,\n",
        "                                                stride=1 , padding = 0, groups = 1),\n",
        "\n",
        "                                    nn.Sigmoid(),\n",
        "\n",
        "                                    )\n",
        "        self.sq = nn.Sequential(\n",
        "                                    nn.AdaptiveAvgPool2d(1),\n",
        "                                    nn.Conv2d(in_chan, in_chan//reduce, 1),\n",
        "                                    nn.ReLU(),\n",
        "                                    nn.Conv2d(in_chan//reduce, in_chan, 1),\n",
        "                                    nn.Sigmoid()\n",
        "                                    )\n",
        "\n",
        "\n",
        "        self.up = nn.Upsample(scale_factor= (up_size1,up_size2) )\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "        x1 = self.Vol1(input)\n",
        "        x2 = self.sq(input)\n",
        "        x3 = torch.mean(x2, dim=1, keepdim= True)\n",
        "        x2 = x3 - nn.ReLU()(x3 - x2)\n",
        "        x = x2 + x1 - x2*x1\n",
        "        x = self.up(x)*input\n",
        "        return x\n",
        "\n",
        "class Branch(nn.Module):\n",
        "    def __init__(self,\n",
        "                  in_cha,\n",
        "                  out_cha,\n",
        "                  kernel_size,\n",
        "                  stride,\n",
        "                  padding,\n",
        "                  in_size\n",
        "                  ):\n",
        "\n",
        "        super(Branch, self).__init__()\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if in_cha != out_cha or stride != 1:\n",
        "            self.shortcut = nn.Sequential( nn.Conv2d(in_cha,\n",
        "                        out_cha,\n",
        "                        kernel_size=1,\n",
        "                        stride= stride  , padding=0,\n",
        "                      bias = False),)\n",
        "\n",
        "        self.Branch1_1 = nn.Sequential(\n",
        "                                  nn.BatchNorm2d( in_cha),\n",
        "                                  nn.ReLU(),\n",
        "\n",
        "                                  nn.Conv2d(in_cha,\n",
        "                                            out_cha,\n",
        "                                            kernel_size = 3,\n",
        "                                            stride= 1, padding = 1,\n",
        "                                            bias = False),\n",
        "\n",
        "                                  )\n",
        "\n",
        "\n",
        "        self.Branch1_2 = nn.Sequential(\n",
        "                                  nn.BatchNorm2d(out_cha),\n",
        "                                  nn.ReLU(),\n",
        "\n",
        "                                  nn.Conv2d( out_cha,\n",
        "                                           out_cha,\n",
        "                                            kernel_size = 3,\n",
        "                                            stride= stride, padding = 1 ,\n",
        "                                            bias = False),\n",
        "\n",
        "                             )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "        x = self.Branch1_1(input)\n",
        "        x =  self.Branch1_2(x) + self.shortcut(input)\n",
        "        return x\n",
        "class Wide_net(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(Wide_net, self).__init__()\n",
        "\n",
        "        self.start_covlayer = nn.Sequential(\n",
        "            nn.Conv2d(1, 14, 3, 1, 1, bias= False),\n",
        "\n",
        "           )\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "\n",
        "                                    Branch(14, 14*k,  3, 1, 1,28),\n",
        "                                    HLA(14*k,  (3, 3), (2, 2), (1, 1), (28, 28), 14),\n",
        "\n",
        "                                    Branch(14*k, 14*k,  3, 1, 1, 28),\n",
        "                                    HLA(14*k,  (3, 3),(2, 2), (1, 1), (28, 28), 14),\n",
        "\n",
        "                                    # Branch(16*k, 16*k,  3, 1, 1, 32),\n",
        "                                    # HLA(16*k,  (3, 3), (2, 2), (1, 1), (32, 32), 16),\n",
        "\n",
        "                                    # Branch(16*k, 16*k,  3, 1, 1, 32),\n",
        "                                    # HLA(16*k,  (3, 3), (2, 2), (1, 1), (32, 32), 16),\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                                    )\n",
        "\n",
        "\n",
        "        self.layer2 = nn.Sequential(\n",
        "\n",
        "                                    Branch(14*k, 28*k,  3, 2, 1,14),\n",
        "                                    HLA(28*k,  (3, 3), (2, 2), (1, 1), (14, 14), 14),\n",
        "\n",
        "                                    Branch(28*k, 28*k,3,1, 1, 14),\n",
        "                                    HLA(28*k,  (3, 3), (2, 2), (1, 1), (14, 14), 14),\n",
        "\n",
        "\n",
        "                                    # Branch(32*k, 32*k,3,1, 1, 16),\n",
        "                                    #HLA(32*k,  (3, 3), (2, 2), (1, 1), (16, 16), 16),\n",
        "\n",
        "                                    # Branch(32*k, 32*k,3,1, 1, 16),\n",
        "                                    #HLA(32*k,  (3, 3), (2, 2), (1, 1), (16, 16), 16),\n",
        "\n",
        "\n",
        "\n",
        "                                    # Branch(32*k, 32*k,3,1, 1, 16),\n",
        "                                    #HLA(32*k,  (3, 3), (2, 2), (1, 1), (16, 16), 16),\n",
        "\n",
        "\n",
        "                                    # Branch(32*k, 32*k,3,1, 1, 16),\n",
        "                                    # HLA(32*k,  (3, 3), (2, 2), (1, 1), (16, 16), 16),\n",
        "\n",
        "                                    )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        self.layer3 = nn.Sequential(\n",
        "\n",
        "                                        Branch(28*k, 64*k,  3, 2, 1, 8),\n",
        "                                        squeeze(64*k,14),\n",
        "\n",
        "                                        Branch(64*k, 64*k, 3,1, 1, 8),\n",
        "\n",
        "                                        squeeze(64*k,14),\n",
        "\n",
        "                                        nn.BatchNorm2d(64*k),\n",
        "\n",
        "                                        nn.ReLU(),\n",
        "\n",
        "                                        nn.AdaptiveAvgPool2d(1) ,\n",
        "\n",
        "\n",
        "                                            )\n",
        "\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "\n",
        "        nn.Linear(64*k, num_classes),\n",
        "\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.start_covlayer(x)\n",
        "\n",
        "        out = self.layer1(out)\n",
        "\n",
        "        out = self.layer2(out)\n",
        "\n",
        "        out = self.layer3(out)\n",
        "\n",
        "        out = torch.flatten(out, start_dim=1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "model = Wide_net(num_classes).to(device)\n",
        "\n",
        "\n",
        "total_step = len(train_loader)\n",
        "num_epochs = 200\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), momentum = 0.9, lr= 0.1,  weight_decay = 0.0005, nesterov=True)\n",
        "\n",
        "scheduler1 = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[60, 120,160], gamma= 0.2)\n",
        "\n",
        "total_params = sum(param.numel() for param in model.parameters())\n",
        "\n",
        "with open('log_WRN_16_8_1.txt', 'w') as f:\n",
        "    f.write('Epochs\\tTraining Loss\\tTraining_acc\\tTesting_acc\\n')\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    model.training = True\n",
        "    train_total = 0\n",
        "    train_correct = 0\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        # Move tensors to the configured device\n",
        "\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        train_total +=labels.size(0)\n",
        "        train_correct +=(predicted == labels).sum().item()\n",
        "\n",
        "    scheduler1.step()\n",
        "    train_acc = 100 * train_correct/train_total\n",
        "\n",
        "    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, train_acc: {:.3f} %'\n",
        "                    .format(epoch+1, num_epochs, i+1, total_step, loss.item(), train_acc))\n",
        "\n",
        "\n",
        "    # Validation\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    model.eval()\n",
        "    model.training = False\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            del images, labels, outputs\n",
        "\n",
        "        print('Accuracy of the network on the {} test images: {} %'.format(10000, 100 * correct / total))\n",
        "        with open('log_WRN_16_8_1.txt', 'a') as f:\n",
        "            f.write('[{}/{}]\\t{:.4f}\\t        {:.3f} %\\t      {:.2f} %\\n'.format(\n",
        "                epoch+1,num_epochs, loss.item(), train_acc, 100 * correct / total))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kf31yRKOqTE2",
        "outputId": "16a184c5-6cd2-4882-a797-4e7b6db7d9e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 12861284.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 346014.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 3195458.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 8348172.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Epoch [1/200], Step [469/469], Loss: 0.0406, train_acc: 95.298 %\n",
            "Accuracy of the network on the 10000 test images: 97.63 %\n",
            "Epoch [2/200], Step [469/469], Loss: 0.0342, train_acc: 98.570 %\n",
            "Accuracy of the network on the 10000 test images: 97.54 %\n",
            "Epoch [3/200], Step [469/469], Loss: 0.0195, train_acc: 98.775 %\n",
            "Accuracy of the network on the 10000 test images: 97.81 %\n",
            "Epoch [4/200], Step [469/469], Loss: 0.0176, train_acc: 98.817 %\n",
            "Accuracy of the network on the 10000 test images: 98.78 %\n",
            "Epoch [5/200], Step [469/469], Loss: 0.1203, train_acc: 98.872 %\n",
            "Accuracy of the network on the 10000 test images: 99.06 %\n",
            "Epoch [6/200], Step [469/469], Loss: 0.0094, train_acc: 98.987 %\n",
            "Accuracy of the network on the 10000 test images: 99.24 %\n",
            "Epoch [7/200], Step [469/469], Loss: 0.0863, train_acc: 98.918 %\n",
            "Accuracy of the network on the 10000 test images: 99.18 %\n",
            "Epoch [8/200], Step [469/469], Loss: 0.1062, train_acc: 98.992 %\n",
            "Accuracy of the network on the 10000 test images: 98.6 %\n",
            "Epoch [9/200], Step [469/469], Loss: 0.0592, train_acc: 99.055 %\n",
            "Accuracy of the network on the 10000 test images: 99.26 %\n",
            "Epoch [10/200], Step [469/469], Loss: 0.0393, train_acc: 99.032 %\n",
            "Accuracy of the network on the 10000 test images: 98.98 %\n",
            "Epoch [11/200], Step [469/469], Loss: 0.0106, train_acc: 98.945 %\n",
            "Accuracy of the network on the 10000 test images: 99.4 %\n",
            "Epoch [12/200], Step [469/469], Loss: 0.0325, train_acc: 98.992 %\n",
            "Accuracy of the network on the 10000 test images: 98.37 %\n",
            "Epoch [13/200], Step [469/469], Loss: 0.0368, train_acc: 98.957 %\n",
            "Accuracy of the network on the 10000 test images: 99.13 %\n",
            "Epoch [14/200], Step [469/469], Loss: 0.0110, train_acc: 99.033 %\n",
            "Accuracy of the network on the 10000 test images: 99.06 %\n",
            "Epoch [15/200], Step [469/469], Loss: 0.0068, train_acc: 98.998 %\n",
            "Accuracy of the network on the 10000 test images: 98.93 %\n",
            "Epoch [16/200], Step [469/469], Loss: 0.0199, train_acc: 99.043 %\n",
            "Accuracy of the network on the 10000 test images: 99.41 %\n",
            "Epoch [17/200], Step [469/469], Loss: 0.0431, train_acc: 98.942 %\n",
            "Accuracy of the network on the 10000 test images: 98.52 %\n",
            "Epoch [18/200], Step [469/469], Loss: 0.0596, train_acc: 99.058 %\n",
            "Accuracy of the network on the 10000 test images: 99.05 %\n",
            "Epoch [19/200], Step [469/469], Loss: 0.0213, train_acc: 99.012 %\n",
            "Accuracy of the network on the 10000 test images: 99.21 %\n",
            "Epoch [20/200], Step [469/469], Loss: 0.0331, train_acc: 99.045 %\n",
            "Accuracy of the network on the 10000 test images: 99.31 %\n",
            "Epoch [21/200], Step [469/469], Loss: 0.0423, train_acc: 99.042 %\n",
            "Accuracy of the network on the 10000 test images: 99.34 %\n",
            "Epoch [22/200], Step [469/469], Loss: 0.0555, train_acc: 99.043 %\n",
            "Accuracy of the network on the 10000 test images: 98.89 %\n",
            "Epoch [23/200], Step [469/469], Loss: 0.0157, train_acc: 99.022 %\n",
            "Accuracy of the network on the 10000 test images: 98.9 %\n",
            "Epoch [24/200], Step [469/469], Loss: 0.0241, train_acc: 99.063 %\n",
            "Accuracy of the network on the 10000 test images: 97.99 %\n",
            "Epoch [25/200], Step [469/469], Loss: 0.0292, train_acc: 99.075 %\n",
            "Accuracy of the network on the 10000 test images: 99.35 %\n",
            "Epoch [26/200], Step [469/469], Loss: 0.0052, train_acc: 99.062 %\n",
            "Accuracy of the network on the 10000 test images: 99.15 %\n",
            "Epoch [27/200], Step [469/469], Loss: 0.0409, train_acc: 99.088 %\n",
            "Accuracy of the network on the 10000 test images: 98.96 %\n",
            "Epoch [28/200], Step [469/469], Loss: 0.0084, train_acc: 99.127 %\n",
            "Accuracy of the network on the 10000 test images: 99.32 %\n",
            "Epoch [29/200], Step [469/469], Loss: 0.0316, train_acc: 99.135 %\n",
            "Accuracy of the network on the 10000 test images: 97.5 %\n",
            "Epoch [30/200], Step [469/469], Loss: 0.0339, train_acc: 99.102 %\n",
            "Accuracy of the network on the 10000 test images: 99.0 %\n",
            "Epoch [31/200], Step [469/469], Loss: 0.0717, train_acc: 99.052 %\n",
            "Accuracy of the network on the 10000 test images: 99.19 %\n",
            "Epoch [32/200], Step [469/469], Loss: 0.1258, train_acc: 99.132 %\n",
            "Accuracy of the network on the 10000 test images: 98.96 %\n",
            "Epoch [33/200], Step [469/469], Loss: 0.0388, train_acc: 99.110 %\n",
            "Accuracy of the network on the 10000 test images: 99.2 %\n",
            "Epoch [34/200], Step [469/469], Loss: 0.0188, train_acc: 99.067 %\n",
            "Accuracy of the network on the 10000 test images: 99.25 %\n",
            "Epoch [35/200], Step [469/469], Loss: 0.0432, train_acc: 99.118 %\n",
            "Accuracy of the network on the 10000 test images: 98.86 %\n",
            "Epoch [36/200], Step [469/469], Loss: 0.0069, train_acc: 99.018 %\n",
            "Accuracy of the network on the 10000 test images: 99.28 %\n",
            "Epoch [37/200], Step [469/469], Loss: 0.0379, train_acc: 99.030 %\n",
            "Accuracy of the network on the 10000 test images: 99.37 %\n",
            "Epoch [38/200], Step [469/469], Loss: 0.0695, train_acc: 99.062 %\n",
            "Accuracy of the network on the 10000 test images: 99.39 %\n",
            "Epoch [39/200], Step [469/469], Loss: 0.0237, train_acc: 99.088 %\n",
            "Accuracy of the network on the 10000 test images: 99.44 %\n",
            "Epoch [40/200], Step [469/469], Loss: 0.0623, train_acc: 99.063 %\n",
            "Accuracy of the network on the 10000 test images: 99.18 %\n",
            "Epoch [41/200], Step [469/469], Loss: 0.0165, train_acc: 99.082 %\n",
            "Accuracy of the network on the 10000 test images: 99.13 %\n",
            "Epoch [42/200], Step [469/469], Loss: 0.0981, train_acc: 99.137 %\n",
            "Accuracy of the network on the 10000 test images: 98.97 %\n",
            "Epoch [43/200], Step [469/469], Loss: 0.0242, train_acc: 99.125 %\n",
            "Accuracy of the network on the 10000 test images: 99.14 %\n",
            "Epoch [44/200], Step [469/469], Loss: 0.0497, train_acc: 99.115 %\n",
            "Accuracy of the network on the 10000 test images: 98.16 %\n",
            "Epoch [45/200], Step [469/469], Loss: 0.0394, train_acc: 99.083 %\n",
            "Accuracy of the network on the 10000 test images: 99.22 %\n",
            "Epoch [46/200], Step [469/469], Loss: 0.0525, train_acc: 99.062 %\n",
            "Accuracy of the network on the 10000 test images: 99.16 %\n",
            "Epoch [47/200], Step [469/469], Loss: 0.0167, train_acc: 99.102 %\n",
            "Accuracy of the network on the 10000 test images: 98.55 %\n",
            "Epoch [48/200], Step [469/469], Loss: 0.0410, train_acc: 99.057 %\n",
            "Accuracy of the network on the 10000 test images: 99.25 %\n",
            "Epoch [49/200], Step [469/469], Loss: 0.0448, train_acc: 99.125 %\n",
            "Accuracy of the network on the 10000 test images: 98.99 %\n",
            "Epoch [50/200], Step [469/469], Loss: 0.0375, train_acc: 99.057 %\n",
            "Accuracy of the network on the 10000 test images: 99.27 %\n",
            "Epoch [51/200], Step [469/469], Loss: 0.0352, train_acc: 99.142 %\n",
            "Accuracy of the network on the 10000 test images: 99.49 %\n",
            "Epoch [52/200], Step [469/469], Loss: 0.0114, train_acc: 99.080 %\n",
            "Accuracy of the network on the 10000 test images: 99.13 %\n",
            "Epoch [53/200], Step [469/469], Loss: 0.0334, train_acc: 99.085 %\n",
            "Accuracy of the network on the 10000 test images: 97.35 %\n",
            "Epoch [54/200], Step [469/469], Loss: 0.0492, train_acc: 99.150 %\n",
            "Accuracy of the network on the 10000 test images: 99.19 %\n",
            "Epoch [55/200], Step [469/469], Loss: 0.0378, train_acc: 99.067 %\n",
            "Accuracy of the network on the 10000 test images: 99.17 %\n",
            "Epoch [56/200], Step [469/469], Loss: 0.0327, train_acc: 99.122 %\n",
            "Accuracy of the network on the 10000 test images: 99.31 %\n",
            "Epoch [57/200], Step [469/469], Loss: 0.0171, train_acc: 99.095 %\n",
            "Accuracy of the network on the 10000 test images: 99.1 %\n",
            "Epoch [58/200], Step [469/469], Loss: 0.0306, train_acc: 99.032 %\n",
            "Accuracy of the network on the 10000 test images: 99.4 %\n",
            "Epoch [59/200], Step [469/469], Loss: 0.0113, train_acc: 99.132 %\n",
            "Accuracy of the network on the 10000 test images: 98.11 %\n",
            "Epoch [60/200], Step [469/469], Loss: 0.0505, train_acc: 99.137 %\n",
            "Accuracy of the network on the 10000 test images: 99.07 %\n",
            "Epoch [61/200], Step [469/469], Loss: 0.0193, train_acc: 99.545 %\n",
            "Accuracy of the network on the 10000 test images: 99.74 %\n",
            "Epoch [62/200], Step [469/469], Loss: 0.0045, train_acc: 99.638 %\n",
            "Accuracy of the network on the 10000 test images: 99.71 %\n",
            "Epoch [63/200], Step [469/469], Loss: 0.0122, train_acc: 99.655 %\n",
            "Accuracy of the network on the 10000 test images: 99.73 %\n",
            "Epoch [64/200], Step [469/469], Loss: 0.0042, train_acc: 99.655 %\n",
            "Accuracy of the network on the 10000 test images: 99.75 %\n",
            "Epoch [65/200], Step [469/469], Loss: 0.0108, train_acc: 99.655 %\n",
            "Accuracy of the network on the 10000 test images: 99.67 %\n",
            "Epoch [66/200], Step [469/469], Loss: 0.0031, train_acc: 99.710 %\n",
            "Accuracy of the network on the 10000 test images: 99.65 %\n",
            "Epoch [67/200], Step [469/469], Loss: 0.0037, train_acc: 99.693 %\n",
            "Accuracy of the network on the 10000 test images: 99.64 %\n",
            "Epoch [68/200], Step [469/469], Loss: 0.0073, train_acc: 99.643 %\n",
            "Accuracy of the network on the 10000 test images: 99.63 %\n",
            "Epoch [69/200], Step [469/469], Loss: 0.0098, train_acc: 99.660 %\n",
            "Accuracy of the network on the 10000 test images: 99.63 %\n",
            "Epoch [70/200], Step [469/469], Loss: 0.0162, train_acc: 99.637 %\n",
            "Accuracy of the network on the 10000 test images: 99.59 %\n",
            "Epoch [71/200], Step [469/469], Loss: 0.0078, train_acc: 99.623 %\n",
            "Accuracy of the network on the 10000 test images: 99.6 %\n",
            "Epoch [72/200], Step [469/469], Loss: 0.0226, train_acc: 99.617 %\n",
            "Accuracy of the network on the 10000 test images: 99.61 %\n",
            "Epoch [73/200], Step [469/469], Loss: 0.0031, train_acc: 99.653 %\n",
            "Accuracy of the network on the 10000 test images: 99.42 %\n",
            "Epoch [74/200], Step [469/469], Loss: 0.0056, train_acc: 99.670 %\n",
            "Accuracy of the network on the 10000 test images: 99.61 %\n",
            "Epoch [75/200], Step [469/469], Loss: 0.0116, train_acc: 99.628 %\n",
            "Accuracy of the network on the 10000 test images: 99.64 %\n",
            "Epoch [76/200], Step [469/469], Loss: 0.0087, train_acc: 99.595 %\n",
            "Accuracy of the network on the 10000 test images: 99.63 %\n",
            "Epoch [77/200], Step [469/469], Loss: 0.0101, train_acc: 99.637 %\n",
            "Accuracy of the network on the 10000 test images: 99.58 %\n",
            "Epoch [78/200], Step [469/469], Loss: 0.0211, train_acc: 99.618 %\n",
            "Accuracy of the network on the 10000 test images: 99.58 %\n",
            "Epoch [79/200], Step [469/469], Loss: 0.0075, train_acc: 99.617 %\n",
            "Accuracy of the network on the 10000 test images: 99.58 %\n",
            "Epoch [80/200], Step [469/469], Loss: 0.0058, train_acc: 99.637 %\n",
            "Accuracy of the network on the 10000 test images: 99.66 %\n",
            "Epoch [81/200], Step [469/469], Loss: 0.0126, train_acc: 99.610 %\n",
            "Accuracy of the network on the 10000 test images: 99.59 %\n",
            "Epoch [82/200], Step [469/469], Loss: 0.0218, train_acc: 99.602 %\n",
            "Accuracy of the network on the 10000 test images: 99.6 %\n",
            "Epoch [83/200], Step [469/469], Loss: 0.0060, train_acc: 99.627 %\n",
            "Accuracy of the network on the 10000 test images: 99.54 %\n",
            "Epoch [84/200], Step [469/469], Loss: 0.0038, train_acc: 99.580 %\n",
            "Accuracy of the network on the 10000 test images: 99.58 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "OWRvZTCvp1Eb"
      }
    }
  ]
}